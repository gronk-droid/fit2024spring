{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE4224 Project 2\n",
    "#### Grant Butler | gbutler2020@my.fit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Retrieval/Cleaning:\n",
    "Here, I will use the Spotify API to get the audio features of the tracks in my library, and create a cleaned pandas dataframe to be used with PCA and t-SNE after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to spotify api\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# use dotenv to import api creds\n",
    "secrets = dotenv_values(\".env\")\n",
    "\n",
    "# making authentication manager for spotipy to communicate with spotify\n",
    "auth_manager = SpotifyClientCredentials(client_id=secrets[\"SPOTIPY_CLIENT_ID\"],\n",
    "                                        client_secret=secrets[\"SPOTIPY_CLIENT_SECRET\"])\n",
    "\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)  # making spotipy object\n",
    "sp.trace = False  # no debugging needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting track ids from playlist\n",
    "\n",
    "# grabbing the track ids and adding them to an array passed into them\n",
    "def show_tracks(results, uriArray):\n",
    "    for i, item in enumerate(results['items']):\n",
    "        track = item['track']\n",
    "        uriArray.append(track['id'])\n",
    "\n",
    "# taking in the tracks from the playlist and grabbing the ids before returning them to a list\n",
    "def get_playlist_track_ids(username, playlist_id):\n",
    "    track_ids = []  # to store track ids\n",
    "    playlist = sp.user_playlist(username, playlist_id)  # get playlist\n",
    "    tracks = playlist['tracks']  # getting tracks from playlist\n",
    "\n",
    "    # loop through the tracks and append them with helper function\n",
    "    while tracks['next']:\n",
    "        tracks = sp.next(tracks)\n",
    "        show_tracks(tracks, track_ids)\n",
    "    return track_ids\n",
    "\n",
    "\n",
    "track_ids = get_playlist_track_ids(secrets['SPOTIFY_USERNAME'],\n",
    "                                   secrets['PLAYLIST_ID'])\n",
    "\n",
    "print(track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# helper function to split up the bigger list of track ids (spotify api limits to 100 tracks)\n",
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "# taking in a chunk at a time, ensuring they are strings, and then adding on the features and returning them\n",
    "def get_audio_features(track_ids):\n",
    "    audio_features = []\n",
    "    for chunk in chunks(track_ids, 100):\n",
    "        chunk = [str(track_id) for track_id in chunk]\n",
    "        audio_features.extend(sp.audio_features(chunk))\n",
    "    return audio_features\n",
    "\n",
    "audio_features = get_audio_features(track_ids)\n",
    "print(json.dumps(audio_features, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ensuring there are no entries without data\n",
    "cleaned_features = [item for item in audio_features if item is not None]\n",
    "\n",
    "# making dataframe from the list of dicts\n",
    "df = pd.DataFrame(cleaned_features)\n",
    "\n",
    "# remove fields that have no bearing on analysis\n",
    "fields_to_remove = [\"analysis_url\", \"track_href\", \"type\", \"uri\"]\n",
    "df = df.drop(columns=fields_to_remove)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Dimensional Reduction:\n",
    "\n",
    "Using PCA, I hope to reduce the number of dimensions that t-SNE needs to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# remove ids for numeric data only\n",
    "df_numeric = df.drop(columns='id')\n",
    "\n",
    "# use standard scaler to centeralize and normalize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# apply PCA\n",
    "pca = PCA(n_components=2) # only 2 dimensions for visualization\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# visualize PCA\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.8)\n",
    "plt.title('PCA Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Visualize PCA in 3D\n",
    "# fig = plt.figure(figsize=(8, 6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], alpha=0.8)\n",
    "# ax.set_title('PCA Visualization in 3D')\n",
    "# ax.set_xlabel('Principal Component 1')\n",
    "# ax.set_ylabel('Principal Component 2')\n",
    "# ax.set_zlabel('Principal Component 3')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking loadings of principal components\n",
    "loadings = pca.components_\n",
    "\n",
    "loadings_df = pd.DataFrame(loadings, columns=df_numeric.columns)\n",
    "\n",
    "print(loadings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance ratio for each component\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Principal Component {i + 1}: Explained Variance Ratio = {ratio:.4f}\")\n",
    "\n",
    "# Plot the cumulative explained variance ratio\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.cumsum(explained_variance_ratio), marker='o', linestyle='-')\n",
    "plt.title('Cumulative Explained Variance Ratio')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# sort the loadings to be the most impactful first\n",
    "\n",
    "loadings_diff = np.abs(np.diff(loadings, axis=0))\n",
    "loadings_diff_sum = loadings_diff.sum(axis=0)\n",
    "loadings_diff_df = pd.DataFrame(\n",
    "    loadings_diff_sum, index=df_numeric.columns, columns=['Sum of Loadings Diff'])\n",
    "\n",
    "loadings_diff_sorted = loadings_diff_df.sort_values(by='Sum of Loadings Diff', ascending=False)\n",
    "\n",
    "print(loadings_diff_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply t-SNE on PCA Data\n",
    "\n",
    "Using *t*-SNE on data from PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# using 2 components for t-SNE for visualization after reducing with PCA\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_pca)\n",
    "\n",
    "# t-SNE results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], alpha=0.8)\n",
    "plt.title('t-SNE Visualization')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using k-means to group the clusters and color them based on that\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 28\n",
    "\n",
    "# apply k-means to t-SNE results\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=523)\n",
    "clusters = kmeans.fit_predict(X_tsne)\n",
    "\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(np.unique(clusters))))\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for cluster_id, color in zip(np.unique(clusters), colors):\n",
    "    cluster_indices = np.where(clusters == cluster_id)[0]\n",
    "    plt.scatter(X_tsne[cluster_indices, 0], X_tsne[cluster_indices,\n",
    "                1], label=f'Cluster {cluster_id}', color=color, alpha=0.8)\n",
    "plt.title('t-SNE Visualization (Clustered)')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend() # legends for whether you see which cluster is which\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the track ids with cluster information \n",
    "cluster_track_ids = {}\n",
    "clusters = clusters.astype(int)\n",
    "cluster_track_ids = [{'track_id': track_id, 'cluster_label': int(cluster_label)}\n",
    "                     for track_id, cluster_label in zip(track_ids, clusters)]\n",
    "\n",
    "sorted_tracks = sorted(cluster_track_ids, key=lambda x: x['cluster_label'])\n",
    "\n",
    "with open('clustered_track_ids.json', 'w') as f:\n",
    "    json.dump(sorted_tracks, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "with open('clustered_track_ids.json', 'r') as f:\n",
    "    sorted_data = json.load(f)\n",
    "\n",
    "sp_2 = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=secrets['SPOTIPY_CLIENT_ID'], \n",
    "                                                 client_secret=secrets['SPOTIPY_CLIENT_SECRET'], \n",
    "                                                 redirect_uri='http://127.0.0.1',\n",
    "                                                 scope='playlist-modify-public'))\n",
    "\n",
    "base_playlist_id = '263kh2wImQQUwntoXUjbvP'\n",
    "\n",
    "for cluster_label in range(num_clusters):\n",
    "    temp_tracks = [item['track_id'] for item in sorted_data if item['cluster_label'] == cluster_label]\n",
    "\n",
    "    playlist_name = f'tsne eg cluster {cluster_label}'\n",
    "    new_playlist = sp_2.user_playlist_create(sp_2.me()['id'], playlist_name, public=True)\n",
    "\n",
    "    sp_2.playlist_add_items(new_playlist['id'], temp_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse4224_project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
